{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577d1d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Age & Gender Detection Model Training Project\n",
    "# Final version with an 80% Training, 20% Testing data split.\n",
    "\n",
    "# ### Stage 1: Import Libraries & Initial Setup ###\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Check for GPU availability and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03bfd156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Data -> Training: 176, Validation: 22, Testing: 22\n",
      "Age Data    -> Training: 100, Validation: 12, Testing: 13\n"
     ]
    }
   ],
   "source": [
    "# ### Stage 2: Data Preparation ###\n",
    "# Define transforms for data augmentation (train) and normalization (val/test)\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([ # Used for both validation and testing\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# --- Dataset Classes (separated from transforms for flexibility) ---\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Skipping corrupted image {img_path}. Error: {e}\")\n",
    "            return None # We will handle this in the DataLoader\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "def load_initial_data(root_dir, task='gender'):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    if task == 'gender':\n",
    "        for label, gender in enumerate(['female', 'male']):\n",
    "            gender_path = os.path.join(root_dir, gender)\n",
    "            if not os.path.isdir(gender_path): continue\n",
    "            for img_name in os.listdir(gender_path):\n",
    "                image_paths.append(os.path.join(gender_path, img_name))\n",
    "                labels.append(label)\n",
    "    elif task == 'age':\n",
    "        for age_folder in os.listdir(root_dir):\n",
    "            folder_path = os.path.join(root_dir, age_folder)\n",
    "            if os.path.isdir(folder_path):\n",
    "                try:\n",
    "                    parts = age_folder.split('-')\n",
    "                    avg_age = (int(parts[0]) + int(parts[1])) / 2.0 if len(parts) == 2 else float(age_folder)\n",
    "                    for img_name in os.listdir(folder_path):\n",
    "                        image_paths.append(os.path.join(folder_path, img_name))\n",
    "                        labels.append(avg_age)\n",
    "                except ValueError: continue\n",
    "    return image_paths, labels\n",
    "    \n",
    "def collate_fn_skip_corrupted(batch):\n",
    "    # Filter out None items from the batch, which happen if an image fails to load\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch:\n",
    "        return torch.tensor([]), torch.tensor([])\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "\n",
    "# --- Dataset Paths ---\n",
    "GENDER_DATA_PATH = './dataset/gender/Training/'\n",
    "AGE_DATA_PATH = './dataset/age/Training/'\n",
    "\n",
    "# --- Load and Split Datasets (80/10/10) ---\n",
    "# Gender\n",
    "gender_paths, gender_labels = load_initial_data(GENDER_DATA_PATH, 'gender')\n",
    "full_gender_dataset = CustomDataset(gender_paths, gender_labels) # Create dataset without transforms first\n",
    "\n",
    "train_size = int(0.8 * len(full_gender_dataset))\n",
    "val_size = int(0.1 * len(full_gender_dataset))\n",
    "test_size = len(full_gender_dataset) - train_size - val_size\n",
    "gender_train_subset, gender_val_subset, gender_test_subset = random_split(full_gender_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Apply the correct transforms to each subset\n",
    "gender_train_dataset = copy.deepcopy(gender_train_subset); gender_train_dataset.dataset.transform = data_transforms['train']\n",
    "gender_val_dataset = copy.deepcopy(gender_val_subset); gender_val_dataset.dataset.transform = data_transforms['val']\n",
    "gender_test_dataset = copy.deepcopy(gender_test_subset); gender_test_dataset.dataset.transform = data_transforms['val']\n",
    "\n",
    "# Age\n",
    "age_paths, age_labels = load_initial_data(AGE_DATA_PATH, 'age')\n",
    "full_age_dataset = CustomDataset(age_paths, age_labels)\n",
    "train_size = int(0.8 * len(full_age_dataset))\n",
    "val_size = int(0.1 * len(full_age_dataset))\n",
    "test_size = len(full_age_dataset) - train_size - val_size\n",
    "age_train_subset, age_val_subset, age_test_subset = random_split(full_age_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "age_train_dataset = copy.deepcopy(age_train_subset); age_train_dataset.dataset.transform = data_transforms['train']\n",
    "age_val_dataset = copy.deepcopy(age_val_subset); age_val_dataset.dataset.transform = data_transforms['val']\n",
    "age_test_dataset = copy.deepcopy(age_test_subset); age_test_dataset.dataset.transform = data_transforms['val']\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "gender_train_loader = DataLoader(gender_train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_skip_corrupted)\n",
    "gender_val_loader = DataLoader(gender_val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_skip_corrupted)\n",
    "gender_test_loader = DataLoader(gender_test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_skip_corrupted)\n",
    "age_train_loader = DataLoader(age_train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_skip_corrupted)\n",
    "age_val_loader = DataLoader(age_val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_skip_corrupted)\n",
    "age_test_loader = DataLoader(age_test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_skip_corrupted)\n",
    "\n",
    "print(f\"Gender Data -> Training: {len(gender_train_dataset)}, Validation: {len(gender_val_dataset)}, Testing: {len(gender_test_dataset)}\")\n",
    "print(f\"Age Data    -> Training: {len(age_train_dataset)}, Validation: {len(age_val_dataset)}, Testing: {len(age_test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b12ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Stage 3: Model Architectures (No changes) ###\n",
    "class ResNet50AgeGenderModel(nn.Module):\n",
    "    def __init__(self): super(ResNet50AgeGenderModel, self).__init__(); self.base_model = models.resnet50(pretrained=True); in_features = self.base_model.fc.in_features; self.base_model.fc = nn.Identity(); self.gender_head = nn.Sequential(nn.Linear(in_features, 512), nn.ReLU(), nn.Dropout(0.5), nn.Linear(512, 1)); self.age_head = nn.Sequential(nn.Linear(in_features, 512), nn.ReLU(), nn.Dropout(0.5), nn.Linear(512, 1));\n",
    "    def forward(self, x): features = self.base_model(x); return self.gender_head(features), self.age_head(features)\n",
    "class MobileNetV2AgeGenderModel(nn.Module):\n",
    "    def __init__(self): super(MobileNetV2AgeGenderModel, self).__init__(); self.base_model = models.mobilenet_v2(pretrained=True); in_features = self.base_model.classifier[1].in_features; self.base_model.classifier = nn.Identity(); self.gender_head = nn.Sequential(nn.Linear(in_features, 256), nn.ReLU(), nn.Dropout(0.5), nn.Linear(256, 1)); self.age_head = nn.Sequential(nn.Linear(in_features, 256), nn.ReLU(), nn.Dropout(0.5), nn.Linear(256, 1));\n",
    "    def forward(self, x): features = self.base_model(x); return self.gender_head(features), self.age_head(features)\n",
    "class EfficientNetAgeGenderModel(nn.Module):\n",
    "    def __init__(self): super(EfficientNetAgeGenderModel, self).__init__(); self.base_model = models.efficientnet_b0(pretrained=True); in_features = self.base_model.classifier[1].in_features; self.base_model.classifier = nn.Identity(); self.gender_head = nn.Sequential(nn.Linear(in_features, 256), nn.ReLU(), nn.Dropout(0.5), nn.Linear(256, 1)); self.age_head = nn.Sequential(nn.Linear(in_features, 256), nn.ReLU(), nn.Dropout(0.5), nn.Linear(256, 1));\n",
    "    def forward(self, x): features = self.base_model(x); return self.gender_head(features), self.age_head(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b84b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Stage 4: Training & Validation Function ###\n",
    "def train_and_validate(model, model_name, gender_train_loader, age_train_loader, gender_val_loader, age_val_loader, num_epochs=15):\n",
    "    model.to(device)\n",
    "    criterion_gender = nn.BCEWithLogitsLoss()\n",
    "    criterion_age = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001) # Use a smaller learning rate for fine-tuning\n",
    "    \n",
    "    print(f'--- Starting Training for {model_name} ---')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- TRAINING PHASE ---\n",
    "        model.train()\n",
    "        running_gender_loss, running_age_loss, gender_corrects = 0.0, 0.0, 0\n",
    "        \n",
    "        age_train_iter = iter(age_train_loader)\n",
    "        progress_bar = tqdm(gender_train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\")\n",
    "        \n",
    "        for gender_inputs, gender_labels in progress_bar:\n",
    "            if gender_inputs.nelement() == 0: continue # Skip empty batches\n",
    "            gender_inputs, gender_labels = gender_inputs.to(device), gender_labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            try: age_inputs, age_labels = next(age_train_iter)\n",
    "            except StopIteration: age_train_iter = iter(age_train_loader); age_inputs, age_labels = next(age_train_iter)\n",
    "            if age_inputs.nelement() == 0: continue\n",
    "            age_inputs, age_labels = age_inputs.to(device), age_labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            gender_outputs, _ = model(gender_inputs); _, age_outputs = model(age_inputs)\n",
    "            loss_gender = criterion_gender(gender_outputs, gender_labels); loss_age = criterion_age(age_outputs, age_labels)\n",
    "            total_loss = loss_gender + loss_age\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_gender_loss += loss_gender.item() * gender_inputs.size(0)\n",
    "            running_age_loss += loss_age.item() * age_inputs.size(0)\n",
    "            preds = torch.sigmoid(gender_outputs) > 0.5\n",
    "            gender_corrects += torch.sum(preds == gender_labels.data)\n",
    "            progress_bar.set_postfix(loss=f\"{total_loss.item():.4f}\")\n",
    "\n",
    "        train_gender_loss = running_gender_loss / len(gender_train_loader.dataset); train_age_mae = running_age_loss / len(age_train_loader.dataset); train_gender_acc = gender_corrects.double() / len(gender_train_loader.dataset)\n",
    "\n",
    "        # --- VALIDATION PHASE ---\n",
    "        model.eval()\n",
    "        val_gender_loss, val_age_loss, val_gender_corrects = 0.0, 0.0, 0\n",
    "        age_val_iter = iter(age_val_loader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for gender_inputs, gender_labels in tqdm(gender_val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "                if gender_inputs.nelement() == 0: continue\n",
    "                gender_inputs, gender_labels = gender_inputs.to(device), gender_labels.to(device).unsqueeze(1)\n",
    "                \n",
    "                try: age_inputs, age_labels = next(age_val_iter)\n",
    "                except StopIteration: age_val_iter = iter(age_val_loader); age_inputs, age_labels = next(age_val_iter)\n",
    "                if age_inputs.nelement() == 0: continue\n",
    "                age_inputs, age_labels = age_inputs.to(device), age_labels.to(device).unsqueeze(1)\n",
    "                \n",
    "                gender_outputs, _ = model(gender_inputs); _, age_outputs = model(age_inputs)\n",
    "                loss_gender = criterion_gender(gender_outputs, gender_labels); loss_age = criterion_age(age_outputs, age_labels)\n",
    "                \n",
    "                val_gender_loss += loss_gender.item() * gender_inputs.size(0); val_age_loss += loss_age.item() * age_inputs.size(0)\n",
    "                preds = torch.sigmoid(gender_outputs) > 0.5\n",
    "                val_gender_corrects += torch.sum(preds == gender_labels.data)\n",
    "\n",
    "        val_gender_loss = val_gender_loss / len(gender_val_loader.dataset); val_age_mae = val_age_loss / len(age_val_loader.dataset); val_gender_acc = val_gender_corrects.double() / len(gender_val_loader.dataset)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train: [Acc: {train_gender_acc:.4f}, MAE: {train_age_mae:.4f}] | \"\n",
    "              f\"Val: [Acc: {val_gender_acc:.4f}, MAE: {val_age_mae:.4f}]\")\n",
    "\n",
    "    print(f'--- Training for {model_name} Complete! ---')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60291cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Stage 5: Testing Function (NEW) ###\n",
    "def test_model(model_architecture, model_path, gender_test_loader, age_test_loader):\n",
    "    print(f\"\\n--- Starting Final Testing for {model_path} ---\")\n",
    "    \n",
    "    model = model_architecture()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    criterion_age = nn.L1Loss()\n",
    "    test_age_loss, test_gender_corrects = 0.0, 0\n",
    "    age_test_iter = iter(age_test_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for gender_inputs, gender_labels in tqdm(gender_test_loader, desc=\"[Final Testing]\"):\n",
    "            if gender_inputs.nelement() == 0: continue\n",
    "            gender_inputs, gender_labels = gender_inputs.to(device), gender_labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            try: age_inputs, age_labels = next(age_test_iter)\n",
    "            except StopIteration: age_test_iter = iter(age_test_loader); age_inputs, age_labels = next(age_test_iter)\n",
    "            if age_inputs.nelement() == 0: continue\n",
    "            age_inputs, age_labels = age_inputs.to(device), age_labels.to(device).unsqueeze(1)\n",
    "\n",
    "            gender_outputs, _ = model(gender_inputs); _, age_outputs = model(age_inputs)\n",
    "            \n",
    "            loss_age = criterion_age(age_outputs, age_labels)\n",
    "            test_age_loss += loss_age.item() * age_inputs.size(0)\n",
    "            preds = torch.sigmoid(gender_outputs) > 0.5\n",
    "            test_gender_corrects += torch.sum(preds == gender_labels.data)\n",
    "\n",
    "    final_age_mae = test_age_loss / len(age_test_loader.dataset)\n",
    "    final_gender_acc = test_gender_corrects.double() / len(gender_test_loader.dataset)\n",
    "\n",
    "    print(\"\\n--- FINAL TEST RESULTS ---\")\n",
    "    print(f\"Model: {model_path}\")\n",
    "    print(f\"  Gender Accuracy on Test Set: {final_gender_acc:.4f}\")\n",
    "    print(f\"  Age MAE on Test Set: {final_age_mae:.4f}\")\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f87fc2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for EFFICIENTNET ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Training]: 100%|██████████| 6/6 [01:09<00:00, 11.51s/it, loss=33.0303]\n",
      "Epoch 1/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train: [Acc: 0.4716, MAE: 58.6599] | Val: [Acc: 0.5909, MAE: 35.5828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Training]: 100%|██████████| 6/6 [01:06<00:00, 11.14s/it, loss=38.2669]\n",
      "Epoch 2/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 | Train: [Acc: 0.6420, MAE: 59.3499] | Val: [Acc: 0.7273, MAE: 34.9668]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Training]: 100%|██████████| 6/6 [01:06<00:00, 11.11s/it, loss=36.3815]\n",
      "Epoch 3/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 | Train: [Acc: 0.7443, MAE: 56.8466] | Val: [Acc: 0.8182, MAE: 34.1495]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Training]: 100%|██████████| 6/6 [01:06<00:00, 11.12s/it, loss=35.1789]\n",
      "Epoch 4/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 | Train: [Acc: 0.8182, MAE: 55.5145] | Val: [Acc: 0.8636, MAE: 32.8771]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 [Training]: 100%|██████████| 6/6 [01:06<00:00, 11.14s/it, loss=32.5387]\n",
      "Epoch 5/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 | Train: [Acc: 0.8125, MAE: 53.4834] | Val: [Acc: 0.8636, MAE: 30.9741]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 [Training]: 100%|██████████| 6/6 [01:07<00:00, 11.19s/it, loss=33.2304]\n",
      "Epoch 6/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 | Train: [Acc: 0.8750, MAE: 51.4855] | Val: [Acc: 0.8636, MAE: 28.6725]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 [Training]: 100%|██████████| 6/6 [01:07<00:00, 11.19s/it, loss=28.4866]\n",
      "Epoch 7/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 | Train: [Acc: 0.8693, MAE: 48.4894] | Val: [Acc: 0.8636, MAE: 25.6587]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 [Training]: 100%|██████████| 6/6 [01:06<00:00, 11.09s/it, loss=24.1122]\n",
      "Epoch 8/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 | Train: [Acc: 0.8750, MAE: 44.6286] | Val: [Acc: 0.8636, MAE: 22.2592]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 [Training]: 100%|██████████| 6/6 [01:06<00:00, 11.12s/it, loss=23.2229]\n",
      "Epoch 9/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 | Train: [Acc: 0.8750, MAE: 41.1288] | Val: [Acc: 0.8636, MAE: 20.1599]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 [Training]: 100%|██████████| 6/6 [01:18<00:00, 13.01s/it, loss=22.9787]\n",
      "Epoch 10/15 [Validation]: 100%|██████████| 1/1 [00:04<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 | Train: [Acc: 0.8920, MAE: 36.8466] | Val: [Acc: 0.8636, MAE: 18.2080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 [Training]: 100%|██████████| 6/6 [01:19<00:00, 13.25s/it, loss=20.1371]\n",
      "Epoch 11/15 [Validation]: 100%|██████████| 1/1 [00:04<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 | Train: [Acc: 0.8807, MAE: 33.5454] | Val: [Acc: 0.8636, MAE: 15.0443]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 [Training]: 100%|██████████| 6/6 [01:09<00:00, 11.59s/it, loss=18.2822]\n",
      "Epoch 12/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 | Train: [Acc: 0.9148, MAE: 29.7282] | Val: [Acc: 0.8636, MAE: 13.4695]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 [Training]: 100%|██████████| 6/6 [01:09<00:00, 11.58s/it, loss=14.6191]\n",
      "Epoch 13/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 | Train: [Acc: 0.8977, MAE: 23.6088] | Val: [Acc: 0.8636, MAE: 11.0238]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 [Training]: 100%|██████████| 6/6 [01:09<00:00, 11.63s/it, loss=11.1859]\n",
      "Epoch 14/15 [Validation]: 100%|██████████| 1/1 [00:04<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 | Train: [Acc: 0.9034, MAE: 19.0689] | Val: [Acc: 0.8636, MAE: 11.1100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 [Training]: 100%|██████████| 6/6 [01:14<00:00, 12.35s/it, loss=12.4815]\n",
      "Epoch 15/15 [Validation]: 100%|██████████| 1/1 [00:03<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 | Train: [Acc: 0.9091, MAE: 17.3838] | Val: [Acc: 0.8636, MAE: 9.2213]\n",
      "--- Training for EFFICIENTNET Complete! ---\n",
      "Model successfully saved as efficientnet_age_gender.pth\n",
      "\n",
      "--- Starting Final Testing for efficientnet_age_gender.pth ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Final Testing]: 100%|██████████| 1/1 [00:03<00:00,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL TEST RESULTS ---\n",
      "Model: efficientnet_age_gender.pth\n",
      "  Gender Accuracy on Test Set: 0.8182\n",
      "  Age MAE on Test Set: 10.5810\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ### Stage 6: Main Execution Block ###\n",
    "def main():\n",
    "    # --- CHOOSE THE MODEL TO TRAIN AND ITS OUTPUT FILENAME HERE ---\n",
    "    # model_architecture = ResNet50AgeGenderModel\n",
    "    # output_filename = 'resnet50_age_gender.pth'\n",
    "    \n",
    "    # model_architecture = MobileNetV2AgeGenderModel\n",
    "    # output_filename = 'mobilenetv2_age_gender.pth'\n",
    "    \n",
    "    model_architecture = EfficientNetAgeGenderModel\n",
    "    output_filename = 'efficientnet_age_gender.pth'\n",
    "\n",
    "    # 1. Train and Validate the Model\n",
    "    model_to_train = model_architecture()\n",
    "    trained_model = train_and_validate(\n",
    "        model=model_to_train, \n",
    "        model_name=output_filename.split('_')[0].upper(),\n",
    "        gender_train_loader=gender_train_loader, \n",
    "        age_train_loader=age_train_loader,\n",
    "        gender_val_loader=gender_val_loader,\n",
    "        age_val_loader=age_val_loader,\n",
    "        num_epochs=15\n",
    "    )\n",
    "    # Save the best model\n",
    "    torch.save(trained_model.state_dict(), output_filename)\n",
    "    print(f\"Model successfully saved as {output_filename}\")\n",
    "\n",
    "    # 2. Perform Final Testing on the Unseen Test Set\n",
    "    test_model(\n",
    "        model_architecture=model_architecture,\n",
    "        model_path=output_filename,\n",
    "        gender_test_loader=gender_test_loader,\n",
    "        age_test_loader=age_test_loader\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
